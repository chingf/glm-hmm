{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churchland Widefield Data\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Running a ARHMM on PCA-transformed neural data\n",
    "- Neural data is transformed with PCA over each brain region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ssm\n",
    "import seaborn as sns\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.linalg as la\n",
    "from collections import OrderedDict\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.io import loadmat\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from ssm import LDS\n",
    "from Session import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import ssm\n",
    "from ssm import HMM\n",
    "from ssm.util import find_permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cm import get_cmap\n",
    "cmap = get_cmap('coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Specify the mouse and session date you are looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse = \"mSM36\"\n",
    "day = \"05-Dec-2017\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and region indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549, 189, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl = session.behavenet_latents\n",
    "bl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Load the data into SESSION, NEUR_DATA, NEUR_DATA_EXCERPT\n",
    "\n",
    "# Sesion, and full neural data\n",
    "session = Session(\"vistrained\", mouse, day)\n",
    "neur_data = session.neural['neural']\n",
    "delay_period_indices = session.get_delay_period(include_stim=True)\n",
    "\n",
    "# Taking the 120-frame excerpt\n",
    "excerpt_indices = []\n",
    "for trial in range(delay_period_indices.shape[0]):\n",
    "    start = delay_period_indices[trial,:][0] - 30\n",
    "    end = delay_period_indices[trial,:][0] + 90\n",
    "    excerpt_indices.append([start, end])\n",
    "trial_choices = session.trialmarkers['ResponseSide']\n",
    "neur_data_excerpt = []\n",
    "for trial in range(neur_data.shape[0]):\n",
    "    indices = excerpt_indices[trial]\n",
    "    neur_data_excerpt.append(\n",
    "        bl[trial,indices[0]:indices[1],:] #change to neur_data\n",
    "        )\n",
    "neur_data_excerpt = np.array(neur_data_excerpt)\n",
    "neur_data_excerpt_copy = neur_data_excerpt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Load the neural region indices: REG_INDXS, REG_NAMES\n",
    "reg_indxs = session.neural['reg_indxs_consolidate'].item()\n",
    "reg_names = session.neural['reg_indxs_consolidate'].dtype.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Generate PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reg_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dec0006f4798>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     )\n\u001b[1;32m      8\u001b[0m pc_data = np.zeros(\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mneur_data_excerpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reg_names' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate PC data from neural data reshaped into a matrix with\n",
    "# components as the covariates\n",
    "n_components = 4\n",
    "(num_trials, num_bins, num_comps) = neur_data_excerpt.shape\n",
    "neur_data_excerpt = neur_data_excerpt.reshape(\n",
    "    (-1, num_comps)\n",
    "    )\n",
    "pc_data = np.zeros(\n",
    "    (neur_data_excerpt.shape[0], len(reg_names)*n_components)\n",
    "    )\n",
    "\n",
    "for idx, reg in enumerate(reg_names):\n",
    "    pca = PCA(n_components=n_components, whiten=True)\n",
    "    reg_idxs = reg_indxs[idx] - 1\n",
    "    transformed_data = pca.fit_transform(\n",
    "        neur_data_excerpt[:, reg_idxs.flatten()]\n",
    "        )\n",
    "    if n_components == 1:\n",
    "        transformed_data = np.squeeze(transformed_data)\n",
    "        pc_data[:, idx] = transformed_data\n",
    "    else:\n",
    "        pc_data[:, idx*n_components:idx*n_components + n_components] = transformed_data\n",
    "    print(\"Region: \" + reg)\n",
    "    print(\"PCA captured variance: \" + str(np.sum(pca.explained_variance_ratio_)))\n",
    "    print()\n",
    "\n",
    "pc_data = pc_data.reshape(\n",
    "    (num_trials, num_bins, len(reg_names)*n_components)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Check predictive power of PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def fit_LR(start_idx, window_length, data, trial_choices):\n",
    "    \"\"\"\n",
    "    Fits a L2-regularized logistic regression model, predicting\n",
    "    left/right licking choice.\n",
    "    \n",
    "    Args\n",
    "        start_idx: index in delay period to start extracting a window\n",
    "            of activity.\n",
    "        window_length: size of the window of activity to extract\n",
    "    \"\"\"\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    # Extracting training and test data\n",
    "    for trial in range(trial_choices.size):\n",
    "        choice = trial_choices[trial]\n",
    "        if np.isnan(choice):\n",
    "            continue\n",
    "        activity = data[trial,start_idx:start_idx+window_length,:]\n",
    "        X.append(activity.flatten())\n",
    "        y.append(int(choice-1))\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Training the model with cross validation\n",
    "    log_reg = LogisticRegressionCV(\n",
    "        Cs=5, cv=5, scoring='accuracy', max_iter=500\n",
    "        )\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    log_reg.fit(X, y)\n",
    "    return log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Do a grid search over start index and window length\n",
    "# Fit logistic regression models\n",
    "window_length = 2\n",
    "results = []\n",
    "\n",
    "start_idxs = range(0, 120, 2)\n",
    "for start_idx in start_idxs:\n",
    "    log_reg = fit_LR(start_idx, window_length, pc_data, trial_choices)\n",
    "    results.append(log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Save the logistic regression models\n",
    "pickle.dump(results, open(\n",
    "    \"pickles/temporaldecoding_neuralpca_\" + mouse + \"_\" + day + \".p\", \"wb\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Extract the results corresponding to window_size = 2\n",
    "with open(\n",
    "    \"pickles/temporaldecoding_neuralpca_\" + mouse + \"_\" + day + \".p\", \"wb\"\n",
    "    ) as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Plot decoding accuracy over time\n",
    "start_frame = []\n",
    "accuracy = []\n",
    "plt.figure(figsize=(7,5))\n",
    "for frame, log_reg in enumerate(results):\n",
    "    if log_reg == None:\n",
    "        continue\n",
    "    start_frame.append(frame*2)\n",
    "    accuracy.append(\n",
    "        np.max(np.mean(log_reg.scores_[1], axis=0))\n",
    "        )\n",
    "plt.xticks(\n",
    "    ticks=[30, 30+18, 30+33, 30+51, 30+84],\n",
    "    labels=['Stim On', 'Stim Off', 'Stim On', 'Stim Off', 'Spouts In'],\n",
    "    rotation=45, fontsize=14\n",
    "    )\n",
    "plt.axvspan(30, 30+18, alpha=0.3, color='red')\n",
    "plt.axvspan(30+33, 30+51, alpha=0.3, color='red')\n",
    "plt.title(\"Choice Decoding with BehaveNet Reconstructions\")\n",
    "plt.ylim((0.5,1))\n",
    "sns.lineplot(x=start_frame, y=accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set the parameters of the ARHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = num_bins # Number of time bins\n",
    "K = 0 # Number of discrete states; a hyperparameter\n",
    "N = 0 # Number of observed dimensions; set in the function\n",
    "num_iters = 100\n",
    "kappa = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [],
   "source": [
    "def fit_arhmm(K, data):\n",
    "    \"\"\"\n",
    "    Fits and returns an ARHMM on the given data\n",
    "    \n",
    "    Args\n",
    "        K: Number of discrete states\n",
    "        Data: a (trials x bins x regions) array\n",
    "    Returns\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    N = data.shape[2]\n",
    "    data = [data[i,:,:] for i in np.arange(data.shape[0])]\n",
    "    \n",
    "    # shuffle the trials\n",
    "    shuff_sequence = [i for i in range(len(data))]\n",
    "    npr.shuffle(shuff_sequence)\n",
    "    shuff_sequence = np.array(shuff_sequence)\n",
    "    \n",
    "    # Divide into training and testing\n",
    "    divider_idx = int(np.ceil(0.8*len(data)))\n",
    "    train_indices = shuff_sequence[:divider_idx]\n",
    "    test_indices = shuff_sequence[divider_idx:]\n",
    "    data_train = [data[i] for i in train_indices]\n",
    "    data_test = [data[i] for i in test_indices]\n",
    "    \n",
    "    # Run the ARHMM\n",
    "    arhmm = HMM(\n",
    "        K, N, observations=\"ar\",\n",
    "        transitions=\"sticky\",\n",
    "        transition_kwargs=dict(kappa=kappa)\n",
    "        )\n",
    "    lls = arhmm.fit(\n",
    "        data_train, method = \"em\",\n",
    "        num_em_iters = num_iters\n",
    "        )\n",
    "    \n",
    "    return arhmm, lls, train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_range = np.arange(2,16,1)\n",
    "K_range = np.array([2,3,4,8,12,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "results['arhmm'] = []\n",
    "results['lls'] = []\n",
    "results['train_indices'] = []\n",
    "results['test_indices'] = []\n",
    "for K in K_range:\n",
    "    arhmm, lls, train_indices, test_indices = fit_arhmm(K, pc_data)\n",
    "    results['arhmm'].append(arhmm)\n",
    "    results['lls'].append(lls)\n",
    "    results['train_indices'].append(train_indices)\n",
    "    results['test_indices'].append(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/arhmm_neural_\" + mouse + \"_\" + day + \".p\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Choose the best $K$ by checking the log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/arhmm_neural_\" + mouse + \"_\" + day + \".p\", \"rb\") as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot log likelihoods if you want to see convergence\n",
    "plt.figure(figsize=(12, 8))\n",
    "all_lls = []\n",
    "for idx, K in enumerate(K_range):\n",
    "    lls = results['lls'][idx]\n",
    "    line = None\n",
    "    color = line.get_color() if line is not None else None\n",
    "    line = plt.plot(lls, lw=1, color=color, label=\"K=%d\"%K)[0]\n",
    "\n",
    "xlim = plt.xlim()\n",
    "plt.xlim(xlim)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare log likelihoods as K increases\n",
    "plt.figure(figsize=(7,5))\n",
    "all_lls = []\n",
    "for idx, K in enumerate(K_range):\n",
    "    lls = results['lls'][idx]\n",
    "    all_lls.append(np.max(lls))\n",
    "plt.plot(K_range, all_lls)\n",
    "plt.xlabel(\"Number of Discrete States\", fontsize=15)\n",
    "plt.ylabel(\"Log Likelihood\", fontsize=15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_K = 12\n",
    "best_K_idx = np.argwhere(K_range == best_K)[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check how well the \"smoothed\" version looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_arhmm = results['arhmm'][best_K_idx]\n",
    "test_indices = results['test_indices'][best_K_idx]\n",
    "train_indices = results['train_indices'][best_K_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "trial = test_indices[npr.randint(test_indices.size)]\n",
    "num_range = np.arange(1,15)\n",
    "test = best_arhmm.smooth(pc_data[trial,:,:])\n",
    "plt.plot(num_range + test[:,num_range], 'k--', label=\"Smoothed\")\n",
    "plt.plot(num_range + pc_data[trial,:,num_range].T, label=\"Real\", color = 'r')\n",
    "plt.title(\"Reconstructions from Trial %d\"%trial)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Plot the inferred states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_states = []\n",
    "for trial in np.arange(pc_data.shape[0]):\n",
    "    states = best_arhmm.most_likely_states(pc_data[trial,:,:])\n",
    "    trial_states.append(states)\n",
    "trial_states = np.array(trial_states)\n",
    "plt.figure(figsize=(15,13))\n",
    "plt.imshow(trial_states)\n",
    "plt.xticks(\n",
    "    ticks=[30, 30+18, 30+33, 30+51, 30+84],\n",
    "    labels=['Stim On', 'Stim Off', 'Stim On', 'Stim Off', 'Spouts In'],\n",
    "    rotation=45, fontsize=14\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Plot inferred states for L/R choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot states for left or right lick choice\n",
    "l_states = []\n",
    "r_states = []\n",
    "for trial, choice in enumerate(trial_choices):\n",
    "    states = best_arhmm.most_likely_states(pc_data[trial,:,:])\n",
    "    if choice == 1:\n",
    "        l_states.append(states)\n",
    "    else:\n",
    "        r_states.append(states)\n",
    "l_states = np.array(l_states)\n",
    "r_states = np.array(r_states)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(l_states)\n",
    "plt.xticks(\n",
    "    ticks=[30, 30+18, 30+33, 30+51, 30+84],\n",
    "    labels=['Stim On', 'Stim Off', 'Stim On', 'Stim Off', 'Spouts In'],\n",
    "    rotation=45, fontsize=14\n",
    "    )\n",
    "plt.title(\"Discrete States for Left Lick Choice\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(r_states)\n",
    "plt.xticks(\n",
    "    ticks=[30, 30+18, 30+33, 30+51, 30+84],\n",
    "    labels=['Stim On', 'Stim Off', 'Stim On', 'Stim Off', 'Spouts In'],\n",
    "    rotation=45, fontsize=14\n",
    "    )\n",
    "plt.title(\"Discrete States for Right Lick Choice\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Plot inferred states for correct/incorrect trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_correctchoice = session.trialmarkers['CorrectSide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the states, separating by correctness of choice\n",
    "correct_states = []\n",
    "error_states = []\n",
    "for trial, choice in enumerate(trial_choices):\n",
    "    correctchoice = trial_correctchoice[trial]\n",
    "    states = best_arhmm.most_likely_states(pc_data[trial,:,:])\n",
    "    if choice == correctchoice:\n",
    "        correct_states.append(states)\n",
    "    else:\n",
    "        error_states.append(states)\n",
    "correct_states = np.array(correct_states)\n",
    "error_states = np.array(error_states)\n",
    "\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.imshow(correct_states)\n",
    "plt.xticks(\n",
    "    ticks=[30, 30+18, 30+33, 30+51, 30+84],\n",
    "    labels=['Stim On', 'Stim Off', 'Stim On', 'Stim Off', 'Spouts In'],\n",
    "    rotation=45, fontsize=14\n",
    "    )\n",
    "plt.title(\"Discrete States for Correct Trials\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(error_states)\n",
    "plt.xticks(\n",
    "    ticks=[30, 30+18, 30+33, 30+51, 30+84],\n",
    "    labels=['Stim On', 'Stim Off', 'Stim On', 'Stim Off', 'Spouts In'],\n",
    "    rotation=45, fontsize=14\n",
    "    )\n",
    "plt.title(\"Discrete States for Error Trials\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
