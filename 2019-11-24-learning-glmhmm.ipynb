{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import os\n",
    "import traceback\n",
    "import pickle\n",
    "import pdb\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from LearningSession import *\n",
    "from LearningChoicePredictor import *\n",
    "from LearningPsychometricPredictor import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import ssm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def predict(hmm, X, y):\n",
    "    states = hmm.most_likely_states(\n",
    "        y, input=X\n",
    "        )\n",
    "    pred_y = []\n",
    "    for idx, x in enumerate(X):\n",
    "        state = states[idx]\n",
    "        input_with_constant = np.hstack(\n",
    "            (x, 1)\n",
    "            )\n",
    "        logit_ps = input_with_constant @ hmm.observations.coef[state]\n",
    "        ps = 1/(1 + np.exp(-1*logit_ps))\n",
    "        if ps > 0.5:\n",
    "            pred_y.append(1)\n",
    "        else:\n",
    "            pred_y.append(0)\n",
    "    return np.array(pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     63
    ]
   },
   "outputs": [],
   "source": [
    "def plot_psychometric_clf(clf):\n",
    "    if clf.coef_.size == 2:\n",
    "        data_prevl = []\n",
    "        data_prevr = []\n",
    "        for delta in range(-35,36):\n",
    "            data_prevl.append([0,delta])\n",
    "            data_prevr.append([1,delta])\n",
    "        data_prevl = np.array(data_prevl)\n",
    "        data_prevr = np.array(data_prevr)\n",
    "        psychometric_curve_prevl = clf.predict_proba(data_prevl)\n",
    "        psychometric_curve_prevr = clf.predict_proba(data_prevr)\n",
    "        plt.plot(\n",
    "            range(-35, 36),\n",
    "            psychometric_curve_prevl[:,1], color=\"blue\",\n",
    "            label=\"Previous Choice Left\"\n",
    "            )\n",
    "        plt.plot(\n",
    "            range(-35, 36),\n",
    "            psychometric_curve_prevr[:,1], color=\"red\",\n",
    "            label=\"Previous Choice Right\"\n",
    "            )\n",
    "        plt.title(\"Probability of Choosing Right\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"More Left Beeps >>> More Right Beeps\")\n",
    "        plt.ylim((0,1))\n",
    "        plt.axhline(0.5, color=\"gray\")\n",
    "        plt.axvline(0, color=\"gray\")\n",
    "        plt.show()\n",
    "    elif clf.coef_.size == 3:\n",
    "        array_names = [\n",
    "            \"Auditory; Prev L\",\n",
    "            \"Auditory; Prev R\",\n",
    "            \"Tactile; Prev L\",\n",
    "            \"Tactile; Prev R\"\n",
    "            ]\n",
    "        plot_style = [\"-b\", \"-r\", \"--b\", \"--r\"]\n",
    "        data_arrays = [[] for _ in range(len(array_names))]\n",
    "        for delta in range(-35,36):\n",
    "            data_arrays[0].append([0,delta,1])\n",
    "            data_arrays[1].append([1,delta,1])\n",
    "            data_arrays[2].append([0,delta,0])\n",
    "            data_arrays[3].append([1,delta,0])\n",
    "        data_arrays = [\n",
    "            np.array(d) for d in data_arrays\n",
    "            ]\n",
    "        psycurves = [\n",
    "            clf.predict_proba(d) for d in data_arrays\n",
    "            ]\n",
    "        plt.figure()\n",
    "        for i in range(len(array_names)):\n",
    "            plt.plot(\n",
    "                range(-35, 36),\n",
    "                psycurves[i][:,1], plot_style[i],\n",
    "                label=array_names[i]\n",
    "                )\n",
    "        plt.title(\"Probability of Choosing Right\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"More Left Beeps >>> More Right Beeps\")\n",
    "        plt.ylim((0,1))\n",
    "        plt.axhline(0.5, color=\"gray\")\n",
    "        plt.axvline(0, color=\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "def plot_psychometric_coefs(coefs):\n",
    "    clf = LogisticRegression()\n",
    "    clf.coef_ = np.array([coefs[:-1]])\n",
    "    clf.intercept_ = np.array([coefs[-1]])\n",
    "    plot_psychometric_clf(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def find_best_p_weight(results):\n",
    "    \"\"\"\n",
    "    Assuming results is a dictionary over prior weights. Each entry\n",
    "    of the dictionary is a list of 20 runs of the GLMHMM\n",
    "    \"\"\"\n",
    "    \n",
    "    best_p_weight = None\n",
    "    best_score = -np.inf\n",
    "    for p_weight in results.keys():\n",
    "        sample_glmhmms = results[p_weight]\n",
    "        sample_scores = [s['test_ll'] for s in sample_glmhmms]\n",
    "        score = max(sample_scores)\n",
    "        if score > best_score:\n",
    "            best_p_weight = p_weight\n",
    "            best_score = score\n",
    "    return best_p_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"tacaud\"\n",
    "results_K = pickle.load(open(\n",
    "    filename + \"_glmhmm_results.p\", \"rb\"\n",
    "    ))\n",
    "data = pickle.load(open(\n",
    "    \"pickles/\" + filename + \"_glmhmm_data.p\", \"rb\"\n",
    "    ))\n",
    "X_test = data[\"X_test\"]\n",
    "y_test = data[\"y_test\"]\n",
    "X_train = data[\"X_train\"]\n",
    "y_train = data[\"y_train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance as a function of latent dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Collect log likelihoods\n",
    "test_lls = []\n",
    "pred_scores = []\n",
    "Ks = []\n",
    "Ks_p_weights = []\n",
    "for K in results_K.keys():\n",
    "    p_weight = find_best_p_weight(results_K[K])\n",
    "    results = results_K[K][p_weight]\n",
    "    Ks_p_weights.append(p_weight)\n",
    "    for result in results:\n",
    "        hmm = result['hmm']\n",
    "        test_lls.append(result['test_ll'])\n",
    "        pred_choices = predict(hmm, X_test, y_test)\n",
    "        pred_score = np.sum(pred_choices == y_test.flatten())/y_test.size\n",
    "        pred_scores.append(pred_score)\n",
    "        Ks.append(K)\n",
    "df = pd.DataFrame({\n",
    "    'Ks': Ks, 'test_lls': test_lls, 'pred_scores': pred_scores\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot Log-Likes as a function of dimensions\n",
    "sns.lineplot(\n",
    "    x=\"Ks\", y=\"test_lls\", data=df\n",
    "    )\n",
    "plt.ylabel(\"Test Set Log Likelihood\")\n",
    "plt.xlabel(\"Number of States\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Log-Likes as a function of dimensions\n",
    "sns.lineplot(\n",
    "    x=\"Ks\", y=\"pred_scores\", data=df\n",
    "    )\n",
    "plt.ylabel(\"Test Set Predictive Accuracy\")\n",
    "plt.xlabel(\"Number of States\")\n",
    "plt.ylim(0.5, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ks_p_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing inferred psychometric curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "p_weight = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results_K[K][p_weight]\n",
    "results_test_lls = [r['test_ll'] for r in results]\n",
    "hmm = results[np.argmax(results_test_lls)]['hmm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_psychometric_coefs(hmm.observations.coef[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_psychometric_coefs(hmm.observations.coef[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing accuracy: predicted states and predicted choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_test = hmm.most_likely_states(\n",
    "    y_test, input=X_test\n",
    "    )\n",
    "predicted_train = hmm.most_likely_states(\n",
    "    y_train, input=X_train\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,0.5))\n",
    "plt.imshow(\n",
    "    predicted_test.reshape((1,-1)),\n",
    "    aspect=\"auto\")\n",
    "plt.xlabel(\"Trial Number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,0.5))\n",
    "plt.imshow(\n",
    "    predicted_train.reshape((1,-1)),\n",
    "    aspect=\"auto\")\n",
    "plt.xlabel(\"Trial Number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'mSM63'\n",
    "folder = '/home/chingf/engram/data/musall/learning/neural/mSM63'\n",
    "dates = os.listdir(folder)\n",
    "dates.sort()\n",
    "dates = dates[1:]\n",
    "dates.sort(key = lambda date: datetime.strptime(date, '%d-%b-%Y')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "def _form_data_matrix(task_type):\n",
    "    aud_dates = dates[41:68]\n",
    "    audtac_dates = dates[31:41]\n",
    "    tacaud_dates = dates[41:68]\n",
    "    if task_type == \"aud\":\n",
    "        task_dates = aud_dates\n",
    "        multimodal = False\n",
    "    elif task_type == \"audtac\":\n",
    "        task_dates = aud_dates\n",
    "        multimodal = True\n",
    "    elif task_type == \"tacaud\":\n",
    "        task_dates = aud_dates\n",
    "        multimodal = True\n",
    "    all_X = []\n",
    "    all_y = []\n",
    "    all_indices = []\n",
    "    is_aud_trial = []\n",
    "    curr_index = 0\n",
    "\n",
    "    for date_idx, date in enumerate(task_dates):\n",
    "        session = LearningSession(\n",
    "            animal, date, access_engram=True, load_neural=False\n",
    "            )\n",
    "        predictor = LearningPsychometricPredictor(\n",
    "            session, multimodal=multimodal)\n",
    "        trial_choices = predictor.trial_choices\n",
    "        nonnan_choices = np.logical_not(np.isnan(trial_choices))\n",
    "        nonnan_data = np.ones((nonnan_choices.shape)).astype(bool)\n",
    "        for trial in range(predictor.data.shape[0]):\n",
    "            if np.sum(np.isnan(predictor.data[trial,:])) > 0:\n",
    "                nonnan_data[trial] = False\n",
    "        nonnan_indices = np.logical_and(nonnan_choices, nonnan_data)\n",
    "        y = trial_choices[nonnan_indices].astype(int) - 1\n",
    "        y = y.reshape((-1,1))\n",
    "        X = predictor.data[nonnan_indices,:]\n",
    "        for idx in nonnan_indices:\n",
    "            is_aud_trial.append(session.is_aud_trial[idx])\n",
    "        indices = np.vstack(\n",
    "            (np.arange(y.size) + curr_index, np.ones(y.size)*date_idx)\n",
    "            ).T\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "        all_indices.append(indices)\n",
    "        curr_index += y.size\n",
    "    all_X = np.vstack(all_X)\n",
    "    all_y = np.vstack(all_y)\n",
    "    all_indices = np.vstack(all_indices)\n",
    "    if task_type == \"aud\":\n",
    "        filename = task_type + \"_glmhmm_data.p\"\n",
    "        _split_data_and_save(all_X, all_y, all_indices, filename)\n",
    "    else:\n",
    "        is_tac_trial = np.logical_not(is_aud_trial)\n",
    "        aud_filename = task_type + \"_aud_glmhmm_data.p\"\n",
    "        aud_X = all_X[is_aud_trial]\n",
    "        aud_y = all_y[is_aud_trial]\n",
    "        aud_indices = all_indices[is_aud_trial]\n",
    "        _split_data_and_save(\n",
    "            aud_X, aud_y, aud_indices, aud_filename\n",
    "            )\n",
    "        tac_filename = task_type + \"_tac_glmhmm_data.p\"\n",
    "        tac_X = all_X[is_tac_trial]\n",
    "        tac_y = all_y[is_tac_trial]\n",
    "        tac_indices = all_indices[is_tac_trial]\n",
    "        _split_data_and_save(\n",
    "            tac_X, tac_y, tac_indices, tac_filename\n",
    "            )\n",
    "    \n",
    "def _split_data_and_save(all_X, all_y, all_indices, filename):\n",
    "    X_train, X_test, y_train, y_test, train_indices, test_indices = \\\n",
    "    train_test_split(\n",
    "        all_X, all_y, all_indices, test_size = 0.20, stratify=all_y\n",
    "        )\n",
    "    data = {\n",
    "        \"X_train\": X_train, \"X_test\": X_test,\n",
    "        \"y_train\":y_train, \"y_test\": y_test,\n",
    "        \"train_indices\": train_indices, \"test_indices\": test_indices\n",
    "        }\n",
    "    pickle.dump(data, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_type = \"tacaud\"\n",
    "_form_data_matrix(task_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
