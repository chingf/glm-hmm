{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import os\n",
    "import traceback\n",
    "import pickle\n",
    "import pdb\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from LearningSession import *\n",
    "from LearningChoicePredictor import *\n",
    "from LearningPsychometricPredictor import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'mSM63'\n",
    "folder = '/home/chingf/engram/data/musall/learning/neural/mSM63'\n",
    "dates = os.listdir(folder)\n",
    "dates.sort()\n",
    "dates = dates[1:]\n",
    "dates.sort(key = lambda date: datetime.strptime(date, '%d-%b-%Y')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load choice decoding results\n",
    "choicedecoders = pickle.load(\n",
    "    open(\"pickles/choicedecodingreduce1.0_learning_mSM63.p\", \"rb\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "def _form_data_matrix(task_type):\n",
    "    aud_dates = range(21, 31)\n",
    "    audtac_dates = range(31, 41)\n",
    "    tacaud_dates = range(41, 68)\n",
    "    if task_type == \"aud\":\n",
    "        task_dates = aud_dates\n",
    "        multimodal = False\n",
    "    elif task_type == \"audtac\":\n",
    "        task_dates = audtac_dates\n",
    "        multimodal = True\n",
    "    elif task_type == \"tacaud\":\n",
    "        task_dates = tacaud_dates\n",
    "        multimodal = True\n",
    "    all_X = []\n",
    "    all_y = []\n",
    "    all_indices = []\n",
    "    is_aud_trial = []\n",
    "    curr_index = 0\n",
    "\n",
    "    for date_idx, day_number in enumerate(task_dates):\n",
    "        date = dates[day_number]\n",
    "        session = LearningSession(\n",
    "            animal, date, access_engram=True, load_neural=False\n",
    "            )\n",
    "        predictor = LearningPsychometricPredictor(\n",
    "            session, multimodal=multimodal)\n",
    "        \n",
    "        # Collect behavioral covariates\n",
    "        y = predictor.trial_choices\n",
    "        X = predictor.data\n",
    "        \n",
    "        # Add in choice decoder predictive probability\n",
    "        # Frames 0-10 are pre-stim, 10-30 are during stim, 30-40 are post-stim\n",
    "        choicedecoder = choicedecoders[day_number]\n",
    "        predic_probs = []\n",
    "        for trial in range(1, session.num_trials + 1):\n",
    "            trial_predic_probs = []\n",
    "            for frame in range(len(choicedecoder[\"predic_prob\"])):\n",
    "                prob = choicedecoder[\"predic_prob\"][frame]\n",
    "                trial_labels = choicedecoder[\"trial_labels\"][frame]\n",
    "                idx = np.argwhere(trial_labels == trial)\n",
    "                if idx.size == 0:\n",
    "                    trial_predic_probs.append(np.nan)\n",
    "                else:\n",
    "                    trial_predic_probs.append(prob[idx[0,0], 1])\n",
    "            trial_predic_probs = np.array(trial_predic_probs)\n",
    "            predic_probs.append(trial_predic_probs)\n",
    "        predic_probs = np.array(predic_probs)\n",
    "        pre_stim_prob = np.mean(predic_probs[:,:10], axis=1)\n",
    "        X = np.hstack((X, pre_stim_prob.reshape((-1,1))))\n",
    "        \n",
    "        # Post-process predictors: throw out nan trials\n",
    "        nonnan_covariates = np.logical_not(\n",
    "            np.sum(np.isnan(X), axis=1)\n",
    "            )\n",
    "        nonnan_choices = np.logical_not(np.isnan(y))\n",
    "        nonnan_indices = np.logical_and(nonnan_covariates, nonnan_choices)\n",
    "        y = y[nonnan_indices].astype(int) - 1\n",
    "        y = y.reshape((-1,1))\n",
    "        X = X[nonnan_indices,:]\n",
    "        \n",
    "        # Boolean mask over auditory trials for nonnan trials\n",
    "        for idx, val in enumerate(nonnan_indices):\n",
    "            if not val:\n",
    "                continue\n",
    "            is_aud_trial.append(session.is_aud_trial[idx])\n",
    "            \n",
    "        # Collect into arrays over all relevant sessions\n",
    "        indices = np.vstack(\n",
    "            (np.arange(y.size) + curr_index, np.ones(y.size)*date_idx)\n",
    "            ).T\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "        all_indices.append(indices)\n",
    "        curr_index += y.size\n",
    "    all_X = np.vstack(all_X)\n",
    "    all_y = np.vstack(all_y)\n",
    "    all_indices = np.vstack(all_indices)\n",
    "    \n",
    "    # For testing/debugging\n",
    "    all_X = all_X[:,-1].reshape((-1,1))\n",
    "    \n",
    "    # Debugging \n",
    "    all_X = all_X.flatten()\n",
    "    all_y = all_y.flatten()\n",
    "    all_X = (all_X > 0.5).astype(int)\n",
    "    print(np.sum(all_X == all_y)/all_y.size)\n",
    "    \n",
    "    # Split data if there are modality differences trial-by-trial\n",
    "#     if task_type == \"aud\":\n",
    "#         filename = task_type + \"_neurglmhmm_testdata.p\"\n",
    "#         _split_data_and_save(all_X, all_y, all_indices, filename)\n",
    "#     else:\n",
    "#         is_tac_trial = np.logical_not(is_aud_trial)\n",
    "#         aud_filename = task_type + \"_aud_neurglmhmm_testdata.p\"\n",
    "#         aud_X = all_X[is_aud_trial]\n",
    "#         aud_y = all_y[is_aud_trial]\n",
    "#         aud_indices = all_indices[is_aud_trial]\n",
    "#         _split_data_and_save(\n",
    "#             aud_X, aud_y, aud_indices, aud_filename\n",
    "#             )\n",
    "#         tac_filename = task_type + \"_tac_neurglmhmm_testdata.p\"\n",
    "#         tac_X = all_X[is_tac_trial]\n",
    "#         tac_y = all_y[is_tac_trial]\n",
    "#         tac_indices = all_indices[is_tac_trial]\n",
    "#         _split_data_and_save(\n",
    "#             tac_X, tac_y, tac_indices, tac_filename\n",
    "#             )\n",
    "    \n",
    "def _split_data_and_save(all_X, all_y, all_indices, filename):\n",
    "    data = {\n",
    "        \"X\": all_X, \"y\": all_y, \"indices\": all_indices\n",
    "        }\n",
    "    pickle.dump(data, open(filename, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8554123711340206\n",
      "0.7957174501599803\n",
      "0.8547515720485342\n"
     ]
    }
   ],
   "source": [
    "task_type = \"aud\"\n",
    "_form_data_matrix(task_type)\n",
    "task_type = \"audtac\"\n",
    "_form_data_matrix(task_type)\n",
    "task_type = \"tacaud\"\n",
    "_form_data_matrix(task_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
