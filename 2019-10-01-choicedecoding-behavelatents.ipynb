{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churchland Widefield Data\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Decoding L/R choice from different periods of the delay period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Import Statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ssm\n",
    "import re\n",
    "import seaborn as sns\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.linalg as la\n",
    "from collections import OrderedDict\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.io import loadmat\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from ssm import LDS\n",
    "from Session import *\n",
    "from ChoicePredictor import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cm import get_cmap\n",
    "cmap = get_cmap('coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Specify the mouse and session date you are looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse = \"mSM36\"\n",
    "day = \"05-Dec-2017\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1A. Load relevant classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "session = Session(\"vistrained\", mouse, day)\n",
    "predictor = SVCChoice(session, \"behavenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1B. Fit polynomial-kernel SVC over each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "results = predictor.fit_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the logistic regression models\n",
    "pickle.dump(results, open(\n",
    "    \"pickles/choicedecoding_behavelatents_\" + mouse + \"_\" + day + \".p\", \"wb\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot decoding accuracy over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot decoding accuracy over time\n",
    "start_frame = []\n",
    "accuracy = []\n",
    "neur_accuracy = []\n",
    "plt.figure(figsize=(9,7))\n",
    "for frame, sc in enumerate(scores):\n",
    "    start_frame.append(frame*2)\n",
    "    accuracy.append(\n",
    "        np.mean(sc)\n",
    "        )\n",
    "    \n",
    "    # Now do the same for the full neural data\n",
    "    neur_log_reg = neur_results[frame]\n",
    "    neur_accuracy.append(\n",
    "        np.max(np.mean(neur_log_reg.scores_[1], axis=0))\n",
    "        )\n",
    "plt.xticks(\n",
    "    ticks=[30, 30+18, 30+33, 30+51, 30+84],\n",
    "    labels=['Stim On', 'Stim Off', 'Stim On', 'Stim Off', 'Spouts In'],\n",
    "    rotation=45, fontsize=14\n",
    "    )\n",
    "plt.axvspan(30, 30+18, alpha=0.3, color='red')\n",
    "plt.axvspan(30+33, 30+51, alpha=0.3, color='red')\n",
    "plt.title(\"Choice Decoding\")\n",
    "plt.ylim((0.5,1))\n",
    "sns.lineplot(\n",
    "    x=start_frame, y=accuracy, label=\"BehaveNet Latents\",\n",
    "    linewidth=1.5\n",
    "    )\n",
    "sns.lineplot(\n",
    "    x=start_frame, y=neur_accuracy, label=\"Original Neural Activity\",\n",
    "    linewidth=1.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run LOO Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo_results = predictor.fit_loo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fit LR models for all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "window_lengths = [2,4,6]\n",
    "task = \"vistrained\"\n",
    "taskdir = \"/home/chingf/engram/data/musall/\" + task + \"/\"\n",
    "analysisdir = \"/home/chingf/engram/analysis/behavenet/musall/\" + task + \"/\"\n",
    "\n",
    "def train_models(task, animal, day):\n",
    "    \"\"\"\n",
    "    Fits and returns logistic regression models.\n",
    "    \n",
    "    Args:\n",
    "        task: \"vistrained\" or \"audtrained\"\n",
    "        animal: Name of the animal\n",
    "        day: date of the session\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load session and data\n",
    "    session = Session(task, animal, day, access_engram=True)\n",
    "    behave_latents = session.behavenet_latents\n",
    "    trial_choices = session.trialmarkers['ResponseSide']\n",
    "    delay_latents = []\n",
    "    min_delay_size = 90\n",
    "    delay_period_indices = session.get_delay_period(include_stim=True)\n",
    "    for trial in range(delay_period_indices.shape[0]):\n",
    "        start = delay_period_indices[trial,:][0] - 30\n",
    "        end = delay_period_indices[trial,:][0] + 90\n",
    "        activity = behave_latents[trial, start:end, :]\n",
    "        delay_latents.append(activity)\n",
    "    behave_latents = np.array(delay_latents)\n",
    "    \n",
    "    # Remove gap trials (just nans)\n",
    "    behave_latents_nogap = []\n",
    "    trial_choices_nogap = []\n",
    "    for trial in range(session.num_trials):\n",
    "        activity = behave_latents[trial,:,:]\n",
    "        if np.sum(np.isnan(activity)) > 0:\n",
    "            continue\n",
    "        behave_latents_nogap.append(activity)\n",
    "        trial_choices_nogap.append(trial_choices[trial])\n",
    "    behave_latents = np.array(behave_latents_nogap)\n",
    "    trial_choices = np.array(trial_choices_nogap)\n",
    "    \n",
    "    # Do a grid search over start index and window length\n",
    "    # Fit logistic regression models\n",
    "    all_results = []\n",
    "    for window_length in window_lengths:\n",
    "        start_idxs = range(0, behave_latents.shape[1], 2)\n",
    "        window_results = [None for _ in range(session.num_bins)]\n",
    "        for start_idx in start_idxs:\n",
    "            log_reg = fit_LR(start_idx, window_length, behave_latents, trial_choices)\n",
    "            window_results[start_idx] = log_reg\n",
    "        all_results.append(window_results)\n",
    "        \n",
    "    # Collect the cross-validated accuracy\n",
    "    accuracy_grid = []\n",
    "    for idx, window_length in enumerate(window_lengths):\n",
    "        window_results = all_results[idx]\n",
    "        window_accuracy = []\n",
    "        for results in window_results:\n",
    "            if results == None:\n",
    "                window_accuracy.append(0)#np.isnan)\n",
    "                continue\n",
    "            score = np.max(np.mean(results.scores_[1], axis=0))\n",
    "            window_accuracy.append(score)\n",
    "        accuracy_grid.append(window_accuracy)\n",
    "    accuracy_grid = np.array(accuracy_grid)\n",
    "    \n",
    "    return all_results, accuracy_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def fit_LR(start_idx, window_length, data, trial_choices):\n",
    "    \"\"\"\n",
    "    Fits a L2-regularized logistic regression model, predicting\n",
    "    left/right licking choice.\n",
    "    \n",
    "    Args\n",
    "        start_idx: index in delay period to start extracting a window\n",
    "            of activity.\n",
    "        window_length: size of the window of activity to extract\n",
    "    \"\"\"\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    # Extracting training and test data\n",
    "    for trial in range(trial_choices.size):\n",
    "        choice = trial_choices[trial]\n",
    "        if np.isnan(choice):\n",
    "            continue\n",
    "        activity = data[trial, start_idx:start_idx+window_length, :]\n",
    "        X.append(activity.flatten())\n",
    "        y.append(int(choice-1))\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Training the model with cross validation\n",
    "    log_reg = LogisticRegressionCV(\n",
    "        Cs=5, cv=5, scoring='accuracy',\n",
    "        max_iter=500\n",
    "        )\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    log_reg.fit(X, y)\n",
    "    return log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Run logistic regression over all available sessions\n",
    "all_results = {}\n",
    "all_accuracy = []\n",
    "for animal in os.listdir(taskdir):\n",
    "    if not animal.startswith(\"mSM\"):\n",
    "        continue\n",
    "    if not animal in os.listdir(analysisdir):\n",
    "        continue\n",
    "    animaldir = taskdir + animal + \"/\"\n",
    "    all_results[animal] = {}\n",
    "    for day in os.listdir(animaldir):\n",
    "        if not re.match(\"\\d{2}-\\w+-\\d{4}\", day):\n",
    "            print(\"Invalid directory: \" + day)\n",
    "            continue\n",
    "        if not day in os.listdir(analysisdir + animal + \"/\"):\n",
    "            continue\n",
    "        daydir = animaldir + day + \"/\"\n",
    "        session_results, session_accuracy = train_models(task, animal, day)\n",
    "        all_results[animal][day] = session_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Save the logistic regression models\n",
    "pickle.dump(all_results, open(\"temporaldecoding_behavenet_all.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decoding: Which time periods are most predictive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# If already available, load the logistic regression models\n",
    "with open(\"temporaldecoding_behavenet_all.p\", \"rb\") as f:\n",
    "    all_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Collect and plot the 'accuracy grid' of each session\n",
    "all_accuracy = []\n",
    "for k1 in all_results.keys():\n",
    "    for k2 in all_results[k1].keys():\n",
    "        results = all_results[k1][k2]\n",
    "        # Collect the cross-validated accuracy\n",
    "        accuracy_grid = []\n",
    "        for idx, window_length in enumerate(window_lengths):\n",
    "            window_results = results[idx]\n",
    "            window_accuracy = []\n",
    "            for r in window_results:\n",
    "                if r == None:\n",
    "                    window_accuracy.append(0)#np.isnan)\n",
    "                    continue\n",
    "                score = np.max(np.mean(r.scores_[1], axis=0))\n",
    "                window_accuracy.append(score)\n",
    "            accuracy_grid.append(window_accuracy)\n",
    "        accuracy_grid = np.array(accuracy_grid)\n",
    "        all_accuracy.append(accuracy_grid)\n",
    "        \n",
    "#         # Plot the cross-validated accuracy\n",
    "#         plt.figure(figsize=(10,8))\n",
    "#         plt.imshow(accuracy_grid, cmap=cmap, aspect='auto', clim=(0.5, 1))\n",
    "#         plt.colorbar()\n",
    "#         plt.xlabel(\"Start Frame\")\n",
    "#         plt.ylabel(\"Framesize of Window\")\n",
    "#         plt.yticks(\n",
    "#             ticks=np.arange(len(window_lengths)),\n",
    "#             labels=[1*w for w in window_lengths]\n",
    "#             )\n",
    "#         plt.xticks(\n",
    "#             ticks=np.arange(1, accuracy_grid.shape[1], 10),\n",
    "#             labels=np.arange(1, accuracy_grid.shape[1], 10)\n",
    "#             )\n",
    "#         plt.title(\"Logistic Regression Accuracy\\n\" + k1 + \"    \" + k2)\n",
    "#         plt.show()\n",
    "\n",
    "        # Visualize accuracy just for window lengths of 2\n",
    "        plt.figure()\n",
    "        accuracy = []\n",
    "        start_frame = []\n",
    "        for idx, val in enumerate(accuracy_grid[0,:]):\n",
    "            if val == 0:\n",
    "                continue\n",
    "            accuracy.append(val)\n",
    "            start_frame.append(idx)\n",
    "        plt.plot(start_frame, accuracy)\n",
    "        plt.title(\"Decoding with window length of 2 frames\\n\" + k1 + \"    \" + k2)\n",
    "        plt.ylabel(\"Choice Decoding Accuracy\")\n",
    "        plt.xlabel(\"Start Frame\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Get the mean accuracy grid\n",
    "mean_accuracy = np.zeros((len(window_lengths), 120))\n",
    "accuracy_counts = np.zeros(mean_accuracy.shape)\n",
    "for accuracy in all_accuracy:\n",
    "    for i in range(accuracy.shape[0]):\n",
    "        for j in range(120):\n",
    "            mean_accuracy[i][j] += accuracy[i][j]\n",
    "            accuracy_counts[i][j] += 1\n",
    "\n",
    "mean_accuracy = np.divide(mean_accuracy, accuracy_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the cross-validated accuracy\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(mean_accuracy, cmap=cmap, aspect='auto', clim=(0.5, 1))\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Start Frame\")\n",
    "plt.ylabel(\"Framesize of Window\")\n",
    "plt.yticks(\n",
    "    ticks=np.arange(len(window_lengths)),\n",
    "    labels=[1*w for w in window_lengths]\n",
    "    )\n",
    "plt.title(\"Logistic Regression Accuracy\\nAveraged over all Sessions\\n\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decoding: Which regions are most predictive over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize accuracy just for window lengths of 2\n",
    "\n",
    "# Get all the window length 2 accuracies\n",
    "accuracy_vals = []\n",
    "start_frames = []\n",
    "for accuracy in all_accuracy:\n",
    "    for i in range(accuracy.shape[0]):\n",
    "        for j in range(120):\n",
    "            if accuracy[i][j] == 0:\n",
    "                continue\n",
    "            accuracy_vals.append(accuracy[i][j])\n",
    "            start_frames.append(j)\n",
    "df = pd.DataFrame({\n",
    "    'Accuracy': accuracy_vals,\n",
    "    'Frame': start_frames\n",
    "    })\n",
    "\n",
    "plt.figure(figsize=(9,7))\n",
    "ax = sns.lineplot(x=\"Frame\", y=\"Accuracy\", data=df)\n",
    "plt.title(\"Decoding with window length of 2 frames\\n(All Sessions)\", fontsize=14)\n",
    "plt.ylabel(\"Choice Decoding Accuracy\", fontsize=14)\n",
    "plt.xlabel(\"Start Frame\")\n",
    "plt.xticks(\n",
    "    ticks=[30, 30+18, 30+33, 30+51, 30+84],\n",
    "    labels=['Stim On', 'Stim Off', 'Stim On', 'Stim Off', 'Spouts In'],\n",
    "    rotation=45, fontsize=14\n",
    "    )\n",
    "ax.axvspan(30, 30+18, alpha=0.3, color='red')\n",
    "ax.axvspan(30+33, 30+51, alpha=0.3, color='red')\n",
    "plt.ylim((0.5,1))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
